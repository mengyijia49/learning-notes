# Neptune:Advanced ML Operator Fusion for Locality and Parallelism on GPUs





一句话总结：突破编译技术瓶颈，自动生成媲美Flash Attention的高性能Kernel

本文工作概述：提出了Neptune，一种新颖的张量编译器。Neptune可以融合多个具有复杂数据依赖的归约操作，超出了现有流行张量编译器的能力。

## 1.背景：

Slide 1：

以算子序列表示的深度学习模型->GPU内核

手动优化->张量编译器自动生成高效内核

单独的算子->算子融合

第二页：

注意力机制融合困难

## 2.为什么传统编译器搞不定注意力融合？

朴素融合会导致计算结果错误

传统张量编译器可以做什么？只能朴素融合吗？



2.两个关键问题

1️⃣现有的张量编译器难以融合涉及循环依赖的复杂归约计算

​    一个典型的例子是注意力计算

2️⃣两种主要的张量优化方法单独都不足以找到高性能的优化方案。

​    介绍两类编译器，但是由于两者之间的交互几乎不存在，对于像算子融合这样的全局优化，目前仍需要开发者手动实现。

## 3.Neptune 的核心创新：打破依赖+代数修复



### 创新 1：先进算子融合范式（两大核心算法）



#### 算法1.Rolling Update（滚动更新融合）—— 适合 Prefill 场景



#### 算法2.Split-K Update（拆分 K 融合）—— 适合 Decoding 场景



### 创新 2：调度与 tile 优化的无缝集成





## 4.实验结果：性能碾压主流方案



适用范围与限制

