# Neptune:Advanced ML Operator Fusion for Locality and Parallelism on GPUs

1.背景：

为了让深度学习模型行跑得更快，最关键的优化手段是将高层的“模型架构”（以算子的序列的形式）转化为“GPU指令”。历史上，对于最常用的模型（如Transformer），工程师会手动编写高度优化的Kernal（例如FlashAttention）。

但是，

2.核心问题定义



3.现有方法与不足



4.研究目标与设计原则



5.核心创新点



6.架构和算法



7.实验设置



8.性能结果



9.适用范围与限制



10.总结贡献与未来工作