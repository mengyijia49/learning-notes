算子融合（编译器语境下）：把多个高层算子合并成一个GPU Kernel执行。

张量编译器：由于PyTorch有2000+个算子、模型结构+GPU架构组合爆炸导致手写kernel不可规模化，张量编译器可以解决这个问题。

张量编译器分为两类：Schedule-based和Tile-based。

单独使用以上两类张量编译器都不能找到高性能的优化方案。

基于调度的张量编译器可以，

基于块的张量编译器可以，

单独使用以上两类张量编译器都不能找到高性能的优化方案。但是调度和块优化之间没有交互。于是像算子融合这样的全局优化，目前仍由手动实现。如果想同时利用到TVM的算子融合和Trition的块优化，需要先使用TVM进行算子融合，然后再手动将TVM程序转为Trition程序。